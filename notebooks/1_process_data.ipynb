{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in the end, we want for each hour the following:\n",
    "- DE day-ahead price (+ market closing time)\n",
    "- CH day-ahead price (+ market closing time)\n",
    "- JAO Auction price DE->CH (+ market closing time)\n",
    "- JAO Auction price (CH->DE) (+ market closing time)\n",
    "- for each market closing time some additional predicted weather data or other potential explaining variables\n",
    "\n",
    "0. make sure, you have the some day-ahead price data for both countries in data/raw\n",
    "1. with functions from src/upstream.py we get the data from JAO and put it in data/external\n",
    "2. create a dataset with day-ahead price difference CH-DE per hour, both auction prices, and further variables for that hour that were known at market closing time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append(\"..\")\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import ast\n",
    "from datetime import datetime, timedelta\n",
    "from calendar import monthrange\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the fetch_auction_data function\n",
    "from src.datafeed.upstream import fetch_auction_data\n",
    "\n",
    "from src.config import KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the data from JAO (This data is in CET/CEST!)\n",
    "\n",
    "The dataframe in the first year start on 2th January."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your API key (replace with your actual API key)\n",
    "api_key = KEY\n",
    "\n",
    "# Set the start and end years\n",
    "start_year = 2016\n",
    "end_year = 2022\n",
    "\n",
    "corridors = [\"de-ch\", \"ch-de\"]\n",
    "\n",
    "for corridor in corridors:\n",
    "\n",
    "    # Call the function to fetch and process the data\n",
    "    auction_data = fetch_auction_data(start_year, end_year, api_key, corridor)\n",
    "\n",
    "    # Optionally, display the first few rows of the combined DataFrame\n",
    "    auction_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing the data.\n",
    "x until now, all data is in cet/cest. \n",
    "\n",
    "To do:\n",
    "- DE-LU is in quarter-hours. we should weigh the prices with the forecasted loads so we also get hourly data there. \n",
    "- make functions in src/datafeed/downstream.py to create a dataframe in data/processed\n",
    "    - add data for forecasted loads for both regions (this is before the market closes, estimate by the Transmission System Operators)\n",
    "    - add hourly forecasted weather data (?)\n",
    "    - add other forecasted data (?)\n",
    "    - put all in one easily accessible dataframe for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect day-ahead prices into a single DataFrame (WIP)\n",
    "\n",
    "years = range(2015, 2023)  # Adjust years as necessary\n",
    "path = \"../data/raw/\"  # Update with your actual path\n",
    "\n",
    "bidding_zones = [\"CH\", \"DE-LU\", \"DE-AT-LU\"]\n",
    "bidding_zones_others = [\"DE-LU\", \"DE-AT-LU\"]\n",
    "years = [2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022]\n",
    "\n",
    "# Dictionary to store dataframes\n",
    "dataframes = {}\n",
    "\n",
    "# Dictionary to store concatenated dataframes for each bidding zone\n",
    "df = {}\n",
    "\n",
    "for bidding_zone in bidding_zones:\n",
    "    # List to hold dataframes for a particular bidding zone\n",
    "    dfs = []\n",
    "    for year in years:\n",
    "        # Create a unique key for each dataframe\n",
    "        try:\n",
    "            key = f\"{bidding_zone}_{year}\"\n",
    "            file_name = f\"{path}{bidding_zone}_Day-ahead Prices_{year}.csv\"\n",
    "\n",
    "            # import csv file and store it in the dictionary\n",
    "            dataframes[key] = pd.read_csv(file_name)\n",
    "            dfs.append(dataframes[key])\n",
    "        except:\n",
    "            pass\n",
    "    # concatenating dataframes for each bidding zone\n",
    "    df[bidding_zone] = pd.concat(dfs)\n",
    "\n",
    "    # Ensure the index is a datetime\n",
    "    df[bidding_zone][\"MTU (CET/CEST)\"] = pd.to_datetime(\n",
    "        df[bidding_zone][\"MTU (CET/CEST)\"].str.split(\" - \").str[0],\n",
    "        dayfirst=True,\n",
    "        errors=\"coerce\",\n",
    "    )\n",
    "    df[bidding_zone].sort_values(by=\"MTU (CET/CEST)\", inplace=True)\n",
    "    df[bidding_zone].set_index(\"MTU (CET/CEST)\", inplace=True)\n",
    "    df[bidding_zone][\"Day-ahead Price [EUR/MWh]\"] = pd.to_numeric(\n",
    "        df[bidding_zone][\"Day-ahead Price [EUR/MWh]\"], errors=\"coerce\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CH</th>\n",
       "      <th>DE-LU</th>\n",
       "      <th>DE-AT-LU</th>\n",
       "      <th>de-ch_auctionPrice</th>\n",
       "      <th>de-ch_requestedCapacity</th>\n",
       "      <th>de-ch_offeredCapacity</th>\n",
       "      <th>ch-de_auctionPrice</th>\n",
       "      <th>ch-de_requestedCapacity</th>\n",
       "      <th>ch-de_offeredCapacity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01 00:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.26</td>\n",
       "      <td>1663.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2542.0</td>\n",
       "      <td>4194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 01:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.50</td>\n",
       "      <td>1678.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2542.0</td>\n",
       "      <td>4194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 02:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1678.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2542.0</td>\n",
       "      <td>4194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 03:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.50</td>\n",
       "      <td>1678.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2542.0</td>\n",
       "      <td>4194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 04:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.02</td>\n",
       "      <td>1668.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2542.0</td>\n",
       "      <td>4194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31 19:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.14</td>\n",
       "      <td>2536.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>10977.0</td>\n",
       "      <td>4426.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31 20:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.14</td>\n",
       "      <td>2512.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>10977.0</td>\n",
       "      <td>4426.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31 21:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.09</td>\n",
       "      <td>2524.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10977.0</td>\n",
       "      <td>4426.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31 22:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.75</td>\n",
       "      <td>2516.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>11039.0</td>\n",
       "      <td>4426.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31 23:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.20</td>\n",
       "      <td>2514.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>11040.0</td>\n",
       "      <td>4426.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61361 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     CH  DE-LU  DE-AT-LU  de-ch_auctionPrice  \\\n",
       "datetime                                                       \n",
       "2016-01-01 00:00:00 NaN    NaN       NaN                9.26   \n",
       "2016-01-01 01:00:00 NaN    NaN       NaN                8.50   \n",
       "2016-01-01 02:00:00 NaN    NaN       NaN                8.87   \n",
       "2016-01-01 03:00:00 NaN    NaN       NaN                7.50   \n",
       "2016-01-01 04:00:00 NaN    NaN       NaN               10.02   \n",
       "...                  ..    ...       ...                 ...   \n",
       "2022-12-31 19:00:00 NaN    NaN       NaN               11.14   \n",
       "2022-12-31 20:00:00 NaN    NaN       NaN                8.14   \n",
       "2022-12-31 21:00:00 NaN    NaN       NaN                8.09   \n",
       "2022-12-31 22:00:00 NaN    NaN       NaN                6.75   \n",
       "2022-12-31 23:00:00 NaN    NaN       NaN                4.20   \n",
       "\n",
       "                     de-ch_requestedCapacity  de-ch_offeredCapacity  \\\n",
       "datetime                                                              \n",
       "2016-01-01 00:00:00                   1663.0                  392.0   \n",
       "2016-01-01 01:00:00                   1678.0                  392.0   \n",
       "2016-01-01 02:00:00                   1678.0                  392.0   \n",
       "2016-01-01 03:00:00                   1678.0                  392.0   \n",
       "2016-01-01 04:00:00                   1668.0                  392.0   \n",
       "...                                      ...                    ...   \n",
       "2022-12-31 19:00:00                   2536.0                  374.0   \n",
       "2022-12-31 20:00:00                   2512.0                  374.0   \n",
       "2022-12-31 21:00:00                   2524.0                  374.0   \n",
       "2022-12-31 22:00:00                   2516.0                  374.0   \n",
       "2022-12-31 23:00:00                   2514.0                  374.0   \n",
       "\n",
       "                     ch-de_auctionPrice  ch-de_requestedCapacity  \\\n",
       "datetime                                                           \n",
       "2016-01-01 00:00:00                0.00                   2542.0   \n",
       "2016-01-01 01:00:00                0.00                   2542.0   \n",
       "2016-01-01 02:00:00                0.00                   2542.0   \n",
       "2016-01-01 03:00:00                0.00                   2542.0   \n",
       "2016-01-01 04:00:00                0.00                   2542.0   \n",
       "...                                 ...                      ...   \n",
       "2022-12-31 19:00:00                0.04                  10977.0   \n",
       "2022-12-31 20:00:00                0.02                  10977.0   \n",
       "2022-12-31 21:00:00                0.01                  10977.0   \n",
       "2022-12-31 22:00:00                0.01                  11039.0   \n",
       "2022-12-31 23:00:00                0.01                  11040.0   \n",
       "\n",
       "                     ch-de_offeredCapacity  \n",
       "datetime                                    \n",
       "2016-01-01 00:00:00                 4194.0  \n",
       "2016-01-01 01:00:00                 4194.0  \n",
       "2016-01-01 02:00:00                 4194.0  \n",
       "2016-01-01 03:00:00                 4194.0  \n",
       "2016-01-01 04:00:00                 4194.0  \n",
       "...                                    ...  \n",
       "2022-12-31 19:00:00                 4426.0  \n",
       "2022-12-31 20:00:00                 4426.0  \n",
       "2022-12-31 21:00:00                 4426.0  \n",
       "2022-12-31 22:00:00                 4426.0  \n",
       "2022-12-31 23:00:00                 4426.0  \n",
       "\n",
       "[61361 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a range of years from start_year to end_year (inclusive)\n",
    "years = range(start_year, end_year + 1)\n",
    "\n",
    "# Function to load day-ahead price data for a specific bidding zone across multiple years\n",
    "def load_price_series(bidding_zone, years, path=\"../data/raw/\"):\n",
    "    dfs = []  # List to store DataFrames for each year\n",
    "    for year in years:\n",
    "        # Construct the filename based on the bidding zone and year\n",
    "        filename = f\"{bidding_zone}Day-ahead Prices{year}.csv\"\n",
    "        filepath = os.path.join(path, filename)  # Full path to the file\n",
    "        try:\n",
    "            # Load the CSV file into a DataFrame\n",
    "            df = pd.read_csv(filepath)\n",
    "            # Parse the datetime from the \"MTU (CET/CEST)\" column and use the start time of the interval\n",
    "            df[\"MTU (CET/CEST)\"] = pd.to_datetime(\n",
    "                df[\"MTU (CET/CEST)\"].str.split(\" - \").str[0],  # Extract the start time of the interval\n",
    "                format=\"%d.%m.%Y %H:%M\",  # Specify the format of the datetime\n",
    "                errors=\"coerce\"  # Coerce parsing errors to NaT\n",
    "            )\n",
    "            # Drop duplicate timestamps, keeping the first occurrence (means that one hour of each year is missing because CET/CEST changes,\n",
    "            # but since all dataframes are in CET/CEST, this is not a problem and negligible for our analysis)\n",
    "            df = df.loc[~df[\"MTU (CET/CEST)\"].duplicated()]\n",
    "            # Set the datetime column as the index\n",
    "            df.set_index(\"MTU (CET/CEST)\", inplace=True)\n",
    "            # Append the \"Day-ahead Price\" column to the list of DataFrames\n",
    "            dfs.append(df[\"Day-ahead Price [EUR/MWh]\"])\n",
    "        except Exception as e:\n",
    "            # Ignore missing files or other exceptions and continue\n",
    "            # Uncomment the print statement to debug missing files\n",
    "            #print(f\"Missing {filepath}: {e}\")\n",
    "            continue\n",
    "    # Concatenate all yearly DataFrames if any exist, otherwise return an empty Series\n",
    "    return pd.concat(dfs) if dfs else pd.Series(dtype=float)\n",
    "\n",
    "# Load day-ahead price data for each bidding zone\n",
    "ch_series = load_price_series(\"CH\", years)  # Load data for Switzerland (CH)\n",
    "de_lu_series = load_price_series(\"DE-LU\", years)  # Load data for Germany-Luxembourg (DE-LU)\n",
    "de_at_lu_series = load_price_series(\"DE-AT-LU\", years)  # Load data for Germany-Austria-Luxembourg (DE-AT-LU)\n",
    "\n",
    "# Create a final DataFrame with a unified set of timestamps from all bidding zones\n",
    "all_timestamps = sorted(set(ch_series.index) | set(de_lu_series.index) | set(de_at_lu_series.index))\n",
    "df_final = pd.DataFrame(index=all_timestamps)  # Initialize the final DataFrame with all timestamps as the index\n",
    "\n",
    "# Populate the final DataFrame with price series from each bidding zone\n",
    "df_final['CH'] = ch_series  # Add Swiss prices\n",
    "df_final['DE-LU'] = de_lu_series  # Add German-Luxembourg prices\n",
    "df_final['DE-AT-LU'] = de_at_lu_series  # Add German-Austria-Luxembourg prices\n",
    "\n",
    "# Loop through each corridor and add auction data to the final DataFrame\n",
    "for corridor in corridors:\n",
    "    # Load auction data for the specific corridor\n",
    "    auction_data = pd.read_csv(f\"../data/external/jao_{corridor}.csv\")\n",
    "    # Create a datetime column by combining the date and the start of the productHour range\n",
    "    auction_data['datetime'] = pd.to_datetime(\n",
    "        auction_data['date'] + ' ' + auction_data['productHour'].str.split('-').str[0]\n",
    "    )\n",
    "    # Drop duplicate rows based on the datetime column\n",
    "    auction_data = auction_data.drop_duplicates(subset=['datetime'])\n",
    "    # Set the datetime column as the index\n",
    "    auction_data = auction_data.set_index('datetime')\n",
    "\n",
    "    # Add auction-related columns to the final DataFrame\n",
    "    df_final[f\"{corridor}_auctionPrice\"] = auction_data[f\"{corridor}_auctionPrice\"]\n",
    "    df_final[f\"{corridor}_requestedCapacity\"] = auction_data[f\"{corridor}_requestedCapacity\"]\n",
    "    df_final[f\"{corridor}_offeredCapacity\"] = auction_data[f\"{corridor}_offeredCapacity\"]\n",
    "\n",
    "# Sort the final DataFrame by index (datetime)\n",
    "df_final.sort_index(inplace=True)\n",
    "\n",
    "#create folder \n",
    "processed_folder = '../data/processed'\n",
    "os.makedirs(processed_folder, exist_ok=True)\n",
    "\n",
    "# Save the final merged DataFrame to a CSV file for further analysis\n",
    "df_final.to_csv('../data/processed/merged_data.csv')\n",
    "\n",
    "# Display the final DataFrame\n",
    "df_final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
